
<html>
  <head>
    <meta charset="UTF-8">
    <title>Workshop - Mathematics of data streams</title>
    <style>
      @import url("https://cdn.jsdelivr.net/npm/bootstrap-icons@1.3.0/font/bootstrap-icons.css");
      @import url('https://fonts.googleapis.com/css2?family=Roboto+Mono:wght@400;700&display=swap');
      body {
        font-family: 'Roboto Mono',  monospace;
        font-size: 11pt;
      }
      table {
        margin: 0;
        padding: 0;
        width: 100%;
        font-size: 100%;
        table-layout: fixed;
        border-collapse: collapse;
      }
      h2 small {
        font-weight: normal;
        font-size: 70%;
      }
      td, th {
        padding: 0.5em;
        text-align: center;
      }
      td {
        border: 1px solid;
      }
      .container {
        display: flex;
        width: 70%;
        margin: 0 auto;
        flex-flow: row wrap;
      }
      .content {
        width: 100%;
      }
      .panel {
        flex: 1 0 100%;
      }
      .speakers {
        display: flex;
        flex-flow: row wrap;
        justify-content: space-evenly;
      }
      .right {
        margin-left: 1em;
      }
      .left {
        margin-right: 1em;
      }
      .schedule {
        display: flex;
        flex-flow: column;
        flex: 4 0 auto;
      }
      .logos {
        text-align: center;
        padding-top: 0px;
      }
      .logo {
        /* height: 80px;
        width: auto; */
        width: 20%;
        height: auto;
        margin: 0 1em;
        vertical-align: middle;
        display: inline-block;
      }
      @media (max-width:1414px) {
        .panel {
          flex: 1 0 100%;
        }
        .left, .right {
          margin: 0;
        }
        .logos {
          margin: 1em 0em;
          /* order: 1; */
        }
        .schedule {
          order: 2
        }
        .container{
          width: 95%
        }
      }
      td.time {
        font-weight: bold;
      }
      tr.break {
        background: whitesmoke;
      }
      td.break {
        text-align: center;
        font-weight: bold;
      }
      td.coffee {
        background: whitesmoke;
      }
      td.keynote {
        background: aliceblue;
      }
      td.springschool {
        background: rgb(234, 250, 230)
      }
      a {
        text-decoration: none;
      }
      a:visited {
        color: blue;
      }
      ul {
        padding-inline-start: 0;
      }
      ul li {
        list-style-type: none;
        padding: 0;
        margin: 0;
      }
      p {
        white-space: pre-wrap;
      }
    </style>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  </head>
  <body>
    <div class="container">
      <div class="content">
        <h1>Mathematics of data streams: signatures, neural differential equations, and diffusion models</h1>
        <h2 style="color: gray">8&mdash;9 April, 2024: spring school</h2>
        <h2>10&mdash;13 April, 2024: workshop</h2>
        <h2>Location: Greifswald, Germany</h2>
        <p>The workshop will take place at the <a href="https://www.wiko-greifswald.de/en/directions/">Alfried Krupp Kolleg</a> in Greifswald, Germany. The spring school will take place at the University of Greifswald.</p>
        <p>We kindly ask participants to fill the following: <a href="https://docs.google.com/forms/d/1uvFD05EkVXknVoeTfzKiZIY2aZGzt3KpRSebM_HPAxE/">registration form</a>.</p>
        <p>Transportation and accommodation:<ul>
            <li>&#8226; From abroad: airplane to Berlin, then Berlin to Greifswald via train. Train tickets can be bought on <a href="https://int.bahn.de/en">bahn.de</a> or via the DB Navigator App (Berlin to Greifswald is approx. 2:30 long).</li>
            <li>&#8226; From Greifswald train station to hotels, University and Alfried Krupp Kolleg: all places can be reached on foot.</li>
            <li>&#8226; Accommodation: Greifswald is a small city with limited number of hotels. Please try to book well in advance.</li>
            <li>&#8226; Funding requests: please see the form above.</li>
        </ul></p>
      </div>
      <div class="panel speakers">
        <div style="flex: 1 0 100%">
        <h1>List of speakers</h1>
        </div>
        <div style="flex: 1 0 25%;">
        <h3>Keynote speakers</h3>
        <ul>
          <li>Harald Oberhauser</li>
          <li>Hao Ni</li>
          <li>Yuzuru Inahama</li>
          <li>Kenji Fukumizu</li>
          <li>Valentin de Bortoli</li>
          <li>Adeline Fermanian</li>
        </ul>
        </div>
        <div style="flex: 2 0 auto; margin-right: 100px;">
        <h3 style="margin-bottom:0;">Invited speakers</h3>
        <ul style="float: left;">
          <li>Carlos Amendola</li>
          <li>Kurusch Ebrahimi-Fard</li>
          <li>Darrick Lee</li>
          <li>Antonio Orvieto</li>
          <li>Remi Vaucher</li>
          <li>Maud Lemercier</li>
          <li>Linus Bleistein</li>

        </ul>
        <ul style="float:right;">
            <li>Nikolas Tapia</li>
            <li>Fabian Harang</li>
            <li>Tim Seynnaeve</li>
            <li>Blanka Horvath</li>
            <li>Giovanni Ballarin</li>
            <li>Jeremy Reizenstein</li>
        </ul>
        </div>
        <div style="flex: 1 0 25%;">
          <h3>Organizing Committee</h3>
          <ul>
            <li>Joscha Diehl</li>
            <li>Marianne Clausel</li>
            <li>Konstantin Usevich</li>
            <li>Nozomi Sugiura</li>
            <li>Stephane Chretien</li>
            <li>Leonard Schmitz</li>
            <li>Raphael Mignot</li>
          </ul>
        </div>
      </div>
      <div class="logos">
        <!-- <img class="logo" height="80" width="286" src="./img/DFG-logo.png"/>
        <img class="logo" height="80" width="272" src="./img/UG-logo.svg"/>
        <img class="logo" height="80" width="278" src="./img/WIKO-logo.svg"/> -->
        <img class="logo" src="./img/DFG-logo.png"/>
        <img class="logo" src="./img/UG-logo.svg"/>
        <img class="logo" src="./img/WIKO-logo.svg"/>
        <img class="logo" src="./img/SFDS-logo.png"/>
      </div>
      <div class="panel">
        <div class="schedule">
        <h1>Schedule</h1>
        All times CET (GMT+2)
        <div style="display: inline-block; position: relative;"><div style="display: inline-block; background-color: rgb(234, 250, 230); border: 1px solid black; height: 15px; width: 20px; position: absolute; top: 50%; transform: translateY(-50%);"></div><div style="display:inline-block; margin-left:2em;">spring school</div>, <div style="display: inline-block; background-color: aliceblue; border: 1px solid black; height: 15px; width: 20px; position: absolute; top: 50%; transform: translateY(-50%);"></div><div style="display:inline-block; margin-left:2em;">keynote</div>,  <div style="display: inline-block; background-color: whitesmoke; border: 1px solid black; height: 15px; width: 20px; position: absolute; top: 50%; transform: translateY(-50%);"></div><div style="display:inline-block; margin-left:2em;">break</div></div>
        <table>
          <tr><th></th><th>Monday 8</th><th>Tuesday 9</th><th>Wednesday 10</th><th>Thursday 11</th><th>Friday 12</th><th>Saturday 13</th></tr>
          <tr><th class="time">09:00&ndash;09:30</td><td rowspan="2" class="springschool">Diffusion models (de Bortoli)</td><td rowspan="2" class="springschool">Neural ODEs (Fermanian + Bleistein)</td><td rowspan="2" class="keynote">Plenary (Oberhauser)</td><td rowspan="2" class="keynote">Plenary (Fermanian)</td><td rowspan="2" class="keynote">Plenary (TBD)</td><td rowspan="2" class="keynote">Plenary (Ni)</td></tr>
          <tr><th class="time">09:30&ndash;10:00</td></tr>
          <tr class="break"><th class="time">10:00&ndash;10:30</td><td colspan=6 class="break">Coffee Break</td></tr>
          <tr><th class="time">10:30&ndash;11:00</td><td rowspan="3" class="springschool">Diffusion models (de Bortoli)</td><td rowspan="3" class="springschool">Neural ODEs (Fermanian + Bleistein)</td><td>Talk (Lemercier)</td><td>Talk (Ebrahimi-Fard)</td><td>Talk (Harang)</td><td>Talk (TDB)</td></tr>
          <tr><th class="time">11:00&ndash;11:30</td><td>Talk (Amendola)</td><td>Talk (Orvieto)</td><td>Talk (Tapia)</td><td rowspan="2" class="keynote">Plenary (TBD)</td></tr>
          <tr><th class="time">11:30&ndash;12:00</td><td>Talk (Lee)</td><td>Talk (Horvath)</td><td>Talk (TBD)</td></tr>
          <tr class="break"><th class="time">12:00&ndash;13:00</td><td colspan=6 class="break">Lunch</td></tr>
          <tr><th class="time">13:00&ndash;13:30</td><td rowspan="6" class="springschool">Diffusion models (de Bortoli)</td><td rowspan="6" class="springschool">Neural ODEs (Fermanian + Bleistein)</td><td rowspan="3">Gong talks</td><td>Talk (Seynnaeve)</td><td rowspan="4">Applications afternoon (Chairman: Chretien) (with Vaucher, Ballarin, Sugiura)</td><td>End</td></tr>
          <tr><th class="time">13:30&ndash;14:00</td><td>Talk (Reizenstein)</td></tr>
          <tr><th class="time">14:00&ndash;14:30</td><td>Talk (TBD)</td></tr>
          <tr><th class="time">14:30&ndash;15:00</td><td rowspan="3">Posters + coffee</td><td rowspan="3">Posters + coffee</td></tr>
          <tr><th class="time">15:00&ndash;15:30</td><td rowspan="2" class="coffee">Discussion + coffee</td></tr>
          <tr><th class="time">15:30&ndash;16:00</td></tr>
          <tr><th class="time">16:00&ndash;16:30</td><td rowspan="2" class="coffee">Discussion + coffee</td><td rowspan="2" class="coffee">Discussion + coffee</td><td rowspan="2" class="keynote">Plenary (Inahama)</td><td rowspan="2" class="keynote">Plenary (Fukumizu)</td><td rowspan="2" class="keynote">Plenary (TBD)</td></tr>
          <tr><th class="time">16:30&ndash;17:00</td></tr>
        </table>
        </div>
        Note: it is not a definitive schedule as some slots might be swapped in the future.
      </div>
      <div class="panel">
        <h1>Abstracts</h1>
        <h1>Spring school</h1>
        <h2>Valentin de Bortoli (ENS Ulm)</h2>
        <h3>Introduction to diffusion models</h3>
        <p>Denoising diffusion models are a new paradigm in the field of generative modeling in machine learning. In the past three years all recent state-of-the-art models have relied on this technique (image and music synthesis, video and 3D generation, protein modeling...). In this talk, I will introduce the basics of generative modeling and diffusion models from a statistical point of view. I will discuss some practical and theoretical properties of these models and present some open questions in the field.</p>
        <h2>Adeline Fermanian (Califrais) and Linus Bleistein (Inria Paris)</h2>
        <h3>Neural ODEs</h3>
        <p>TBD.</p>
        
        <h1>Keynotes</h1>
        <h2>Yuzuru Inahama (Kyushu University)</h2>
        <h3>Wong-Zakai approximation of density functions</h3>
        <p>We discuss the Wong-Zakai approximation of probability density functions of solutions (at a fixed time) of rough differential equations driven by fractional Brownian rough path with Hurst parameter H (1/2 >= H > 1/4). Besides rough path theory, we also use Hu-Watanabe's approximation theorem in the framework of Watanabe's distributional Malliavin calculus. When H=1/2, the random rough differential equations coincide with the corresponding Stratonovich-type stochastic differential equations. Even for that case, our main result seems new.</p>
        <h2>Adeline Fermanian (Califrais)</h2>
        <h3>Dynamic Survival Analysis with Controlled Latent States</h3>
        <p>TBD.</p>
        
        <h1>Invited talks</h1>
        <h2>Fabian Harang (BI Norwegian Business School)</h2>
        <h3>On the Signature of an Image</h3>
        <p>An analytic and algebraic understanding of iterated integral signatures associated to continuous paths has played a central role in in a wide range of mathematical areas, such as the construction of stochastic integration for non-martingales with rough paths theory, to formal representations and expansions of solutions to (partial) differential equations. In recent years, the signature has proven to be an efficient feature map for machine learning tasks, where the learning task is related to time series data, or data streams. In contrast to time series data, image data can naturally be seen as two-parameter fields taking values in multi-dimensional space, and in recent years there has been some research into the extension of the path signature to multi-parameter fields (see e.g. Chouk/Gubinelli 14, Lee/Oberhauser (21 and 23)). In this talk I will propose an new extension of the path signature to two-parameter fields motivated by expansions of solutions to certain hyperbolic PDEs with multiplicative noise. The algebraic structure of this object turns out to be rather complicated and I will discuss our current understanding of the challenges with going from 1 to 2 parameters, and provide some interesting observations related to a Chen type relation and a Shuffle type relation. At last I will briefly discuss the universality of the 2D signature, providing a universal approximation theorem, and discuss some open problems. This talk is based on forthcoming joint work with Joscha Diehl, Kurusch Ebrahimi-Fard, and Samy Tindel, and is part of the Signatures for Images project for 2023/2024 at CAS.</p>
        <h2>Antonio Orvieto (ELLIS Institute Tübingen)</h2>
        <h3>Accurate and Efficient Processing of Long Sequences and Large Graphs without Attention</h3>
        <p>When applied to sequential data, transformers have an inherent challenge: their attention mechanism leads to quadratic complexity with respect to sequence length. This issue extends to graph transformers, where complexity scales quadratically with the number of nodes in the network. Today, we'll explore theoretically grounded alternatives to the attention mechanism that hinge on carefully parametrized linear recurrent neural networks. Unlike the more commonly known LSTMs and GRUs, linear RNNs are particularly GPU-efficient. This efficiency enables us to scale up the architecture, successfully study signal propagation, and achieve competitive performance. We'll present how, with a Linear Recurrent Unit (LRU) replacing attention, we can achieve state-of-the-art results on sequence modeling and graph data. This approach offers a promising direction for future research, especially in genetics, protein structure prediction, and audio/video processing and generation. Moreover, the architecture presents interesting connections with the randomized signature approach.</p>
        <h2>Carlos Amendola (TU Berlin)</h2>
        <h3>Convex Hulls of Curves: Volumes and Signatures</h3>
        <p>We study the use of path signatures to compute the volume of the convex hull of a curve. We present sufficient conditions for a curve so that the volume of its convex hull can be computed by such formulae. The canonical example is the classical moment curve, and our class of curves, which we call cyclic, includes other known classes such as d-order curves and curves with totally positive torsion. We also conjecture a necessary and sufficient condition on curves for the signature volume formula to hold. Joint work with Darrick Lee and Chiara Meroni.</p>
        <h2>Maud Lemercier (University of Oxford)</h2>
        <h3>A high-order numerical method for computing signature kernels</h3>
        <p>Signature kernels are at the core of several machine learning algorithms for analysing multivariate time series. The kernels of bounded variation paths, such as piecewise linear interpolations of time series data, are typically computed by solving a linear hyperbolic second-order PDE. However, this approach becomes considerably less practical for highly oscillatory inputs, due to significant time and memory complexities. To mitigate this issue, I will introduce a high-order method which involves replacing the original PDE, which has rapidly varying coefficients, with a system of coupled equations with piecewise constant coefficients. These coefficients are derived from the first few terms of the log-signatures of the input paths and can be computed efficiently using existing Python libraries.</p>
        <h2>Tim Seynnaeve (KU Leuven)</h2>
        <h3>Decomposing tensor spaces via path signatures</h3>
        <p>The signature of a path is a sequence of tensors whose entries are iterated integrals, playing a key role in stochastic analysis and applications. The set of all signature tensors at a particular level gives rise to the universal signature variety. We show that the parametrization of this variety induces a natural decomposition of the tensor space via representation theory, and connect this to the study of path invariants. We also reveal certain constraints that apply to the rank and symmetry of a signature tensor. This talk is based on joint work with Carlos Améndola, Francesco Galuppi, Ángel David Ríos Ortiz, and Pierpaola Santarsiero.</p>
        <h2>Stephane Chretien (University of Lyon 2)</h2>
        <h3>Signature estimation using Seigal's factorisation formula: anticoncentration and robustification</h3>
        <p>The theory of Signatures is a fast growing field which has demonstrated wide applicability to a large range of applications, from finance to health monitoring. Computing signatures often relies on the assumptions that the signal under study is not corrupted by noise, which is rarely the case in practice. In the present paper, we study the influence of noise on the computation of signature via the theory of anti-concentration. We then propose a median of means (MoM) approach to the estimation problem and give a bound on the estimation error using Rademacher complexity.</p>
      </div>
    </div>
  </body>
</html>
